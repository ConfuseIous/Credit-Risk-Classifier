{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ac95f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Conv2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca3ced4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(OrderedDict([('Age', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('Sex', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('Job', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('Housing', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('Saving_accounts', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('Checking_account', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('Credit_amount', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('Duration', TensorSpec(shape=(None,), dtype=tf.int32, name=None)), ('Purpose', TensorSpec(shape=(None,), dtype=tf.string, name=None)), ('Risk', TensorSpec(shape=(None,), dtype=tf.string, name=None))]), TensorSpec(shape=(None,), dtype=tf.int32, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Load the data (csv file)\n",
    "# data = np.loadtxt('__xid-8214579_2.csv', delimiter=',', skiprows=1, dtype=str)\n",
    "# # Split the data into training and testing sets, 80% split\n",
    "# train_data = data[:int(len(data)*0.8)]\n",
    "# test_data = data[int(len(data)*0.8):]\n",
    "\n",
    "csv_file = '__xid-8214579_2.csv'\n",
    "\n",
    "# Load the data (csv file) as tf.data\n",
    "data = tf.data.experimental.make_csv_dataset(\n",
    "    csv_file,\n",
    "    batch_size=32,\n",
    "    label_name='col',\n",
    "    na_value=\"?\",\n",
    "    num_epochs=1,\n",
    "    ignore_errors=True)\n",
    "    \n",
    "train_size = int(0.8 * 1000)\n",
    "val_size = int(0.2 * 1000)\n",
    "data = data.shuffle(1000)\n",
    "train_dataset = data.take(train_size)\n",
    "val_dataset = data.skip(train_size)\n",
    "val_dataset = val_dataset.take(val_size)\n",
    "\n",
    "# Check the data shape and type\n",
    "print(train_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c24bf32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='Age', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='Job', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Housing', vocabulary_list=('own', 'rent', 'free'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='saving_accounts', vocabulary_list=('little', 'moderate', 'quite rich', 'rich', 'NA'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Checking account', vocabulary_list=('little', 'moderate', 'rich', 'NA'), dtype=tf.string, default_value=-1, num_oov_buckets=0)), NumericColumn(key='Credit amount', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='Duration', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='Purpose', vocabulary_list=('radio/TV', 'education', 'furniture/equipment', 'car', 'business', 'domestic appliances', 'repairs', 'vacation/others'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]\n"
     ]
    }
   ],
   "source": [
    "# Define the feature columns\n",
    "\n",
    "feature_columns = []\n",
    "\n",
    "age = tf.feature_column.numeric_column(\"Age\")\n",
    "feature_columns.append(age)\n",
    "\n",
    "sex = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\"Sex\", [\"male\", \"female\"])\n",
    "sex = tf.feature_column.indicator_column(sex)\n",
    "feature_columns.append(sex)\n",
    "\n",
    "job = tf.feature_column.numeric_column(\"Job\")\n",
    "feature_columns.append(job)\n",
    "\n",
    "housing = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\"Housing\", [\"own\", \"rent\", \"free\"])\n",
    "housing = tf.feature_column.indicator_column(housing)\n",
    "feature_columns.append(housing)\n",
    "\n",
    "saving_accounts = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\"saving_accounts\", [\"little\", \"moderate\", \"quite rich\", \"rich\", \"NA\"])\n",
    "saving_accounts = tf.feature_column.indicator_column(saving_accounts)\n",
    "feature_columns.append(saving_accounts)\n",
    "\n",
    "checking_account = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\"Checking account\", [\"little\", \"moderate\", \"rich\", \"NA\"])\n",
    "checking_account = tf.feature_column.indicator_column(checking_account)\n",
    "feature_columns.append(checking_account)\n",
    "\n",
    "credit_amount = tf.feature_column.numeric_column(\"Credit amount\")\n",
    "feature_columns.append(credit_amount)\n",
    "\n",
    "duration = tf.feature_column.numeric_column(\"Duration\")\n",
    "feature_columns.append(duration)\n",
    "\n",
    "purpose = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "\"Purpose\", [\"radio/TV\", \"education\", \"furniture/equipment\", \"car\", \"business\", \"domestic appliances\", \"repairs\", \"vacation/others\"])\n",
    "purpose = tf.feature_column.indicator_column(purpose)\n",
    "feature_columns.append(purpose)\n",
    "\n",
    "# Verify the feature columns\n",
    "print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5041a7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# Predict the credit risk\n",
    "# Credit risk is a binary classification problem\n",
    "# Credit risk is the last column of the data\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(feature_columns),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.005),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57be7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor. Received: inputs=OrderedDict([('Age', <tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>), ('Sex', <tf.Tensor 'IteratorGetNext:9' shape=(None,) dtype=string>), ('Job', <tf.Tensor 'IteratorGetNext:5' shape=(None,) dtype=int32>), ('Housing', <tf.Tensor 'IteratorGetNext:4' shape=(None,) dtype=string>), ('Saving_accounts', <tf.Tensor 'IteratorGetNext:8' shape=(None,) dtype=string>), ('Checking_account', <tf.Tensor 'IteratorGetNext:1' shape=(None,) dtype=string>), ('Credit_amount', <tf.Tensor 'IteratorGetNext:2' shape=(None,) dtype=int32>), ('Duration', <tf.Tensor 'IteratorGetNext:3' shape=(None,) dtype=int32>), ('Purpose', <tf.Tensor 'IteratorGetNext:6' shape=(None,) dtype=string>), ('Risk', <tf.Tensor 'IteratorGetNext:7' shape=(None,) dtype=string>)]). Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\contextlib.py\", line 135, in __enter__\n        return next(self.gen)\n\n    ValueError: Exception encountered when calling layer \"dense_features\" \"                 f\"(type DenseFeatures).\n    \n    'Checking account_indicator' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$\n    \n    Call arguments received by layer \"dense_features\" \"                 f\"(type DenseFeatures):\n      â€¢ features=OrderedDict([('Age', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Sex', 'tf.Tensor(shape=(None,), dtype=string)'), ('Job', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Housing', 'tf.Tensor(shape=(None,), dtype=string)'), ('Saving_accounts', 'tf.Tensor(shape=(None,), dtype=string)'), ('Checking_account', 'tf.Tensor(shape=(None,), dtype=string)'), ('Credit_amount', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Duration', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Purpose', 'tf.Tensor(shape=(None,), dtype=string)'), ('Risk', 'tf.Tensor(shape=(None,), dtype=string)')])\n      â€¢ cols_to_output_tensors=None\n      â€¢ training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m checkpoint \u001b[39m=\u001b[39m ModelCheckpoint(filepath, save_weights_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, save_freq\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mepoch\u001b[39m\u001b[39m'\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      6\u001b[0m     train_dataset,\n\u001b[0;32m      7\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[0;32m      8\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[0;32m      9\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[checkpoint]\n\u001b[0;32m     10\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filew07bqi01.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    134\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[0;32m    136\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\karan\\anaconda3\\envs\\tf\\lib\\contextlib.py\", line 135, in __enter__\n        return next(self.gen)\n\n    ValueError: Exception encountered when calling layer \"dense_features\" \"                 f\"(type DenseFeatures).\n    \n    'Checking account_indicator' is not a valid scope name. A scope name has to match the following pattern: ^[A-Za-z0-9_.\\\\/>-]*$\n    \n    Call arguments received by layer \"dense_features\" \"                 f\"(type DenseFeatures):\n      â€¢ features=OrderedDict([('Age', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Sex', 'tf.Tensor(shape=(None,), dtype=string)'), ('Job', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Housing', 'tf.Tensor(shape=(None,), dtype=string)'), ('Saving_accounts', 'tf.Tensor(shape=(None,), dtype=string)'), ('Checking_account', 'tf.Tensor(shape=(None,), dtype=string)'), ('Credit_amount', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Duration', 'tf.Tensor(shape=(None,), dtype=int32)'), ('Purpose', 'tf.Tensor(shape=(None,), dtype=string)'), ('Risk', 'tf.Tensor(shape=(None,), dtype=string)')])\n      â€¢ cols_to_output_tensors=None\n      â€¢ training=True\n"
     ]
    }
   ],
   "source": [
    "filepath = r\"C:\\Users\\karan\\Programming\\Python\\Credit-Risk-Classifier\\Final Model\\weights-{epoch:02d}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, save_weights_only=False, save_freq='epoch', verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[checkpoint]\n",
    ")\n",
    "\n",
    "# Plot the training and validation loss\n",
    "\n",
    "# Plot the training and validation accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "76305bdb854acd386dc939fa4741f6cc2ccdc8a760b2c7d31af98df840f84e56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
